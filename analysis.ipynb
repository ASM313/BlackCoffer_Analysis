{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asslamu alaikum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Task 1: Sentiment Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"G:\\BlackCoffer_Analysis\") # set project folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remove Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stopwords import given_stop_words\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crawl import article_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(article_text, given_stop_words):\n",
    "    \n",
    "    msg = article_text.lower()\n",
    "\n",
    "    msg=word_tokenize(msg)\n",
    "    print(f\"Total words in article: {len(msg)}\")\n",
    "\n",
    "    filtered_words=[]\n",
    "\n",
    "    for word in msg:\n",
    "        if word not in given_stop_words:\n",
    "            filtered_words.append(word)\n",
    "\n",
    "    print(f\"After removing stopwords: {len(filtered_words)}\")\n",
    "    return filtered_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Creating a dictionary of Positive and Negative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from positive_and_negative import positive_words, negative_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in positive_words:\n",
    "    if word in given_stop_words:\n",
    "        positive_words.pop(positive_words.index(word))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in negative_words:\n",
    "    if word in given_stop_words:\n",
    "        negative_words.pop(negative_words.index(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Extracting Derived variables\n",
    "> i. Positive Score\n",
    "> ii. Negative Score\n",
    "> iii. Polarity Score\n",
    "> iv. Subjectivity Score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive Score\n",
    "\n",
    "def check_positive_score(article_words, positive_words):\n",
    "    positive_score=0\n",
    "    for word in article_words:\n",
    "        if word in positive_words:\n",
    "            positive_score+=1\n",
    "    \n",
    "    return positive_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "print(check_positive_score(filtered_words, positive_words=positive_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative Score\n",
    "\n",
    "def check_negative_score(article_words, negative_words):\n",
    "    negative_score=0\n",
    "    for word in article_words:\n",
    "        if word in negative_words:\n",
    "            negative_score-=1\n",
    "    \n",
    "    return negative_score*(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print(check_negative_score(filtered_words, negative_words=negative_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polarity Score\n",
    "\n",
    "def check_polarity_score(article_words, positive_score, negative_score):\n",
    "    \n",
    "    polarity_score = (positive_score-negative_score)/((positive_score+negative_score)+0.000001)\n",
    "    \n",
    "    return polarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6399999872000003\n"
     ]
    }
   ],
   "source": [
    "print(check_polarity_score(filtered_words, 41,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subjective Score\n",
    "\n",
    "def check_subjective_score(article_words, positive_score, negative_score):\n",
    "    \n",
    "    subjective_score = (positive_score+negative_score)/(len(article_words)+0.000001)\n",
    "    \n",
    "    return subjective_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0672947509188496\n"
     ]
    }
   ],
   "source": [
    "print(check_subjective_score(filtered_words, 41,9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2: Analysis of Readability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Average Sentence Length = the number of words / the number of sentences\n",
    "\n",
    "- Percentage of Complex words = the number of complex words / the number of words \n",
    "\n",
    "- Fog Index = 0.4 * (Average Sentence Length + Percentage of Complex words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Sentence Length\n",
    "\n",
    "def avg_sentence_length(article_text):\n",
    "    words=word_tokenize(article_text)\n",
    "    sentences=sent_tokenize(article_text)\n",
    "    \n",
    "    return len(words)/len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.541666666666664\n"
     ]
    }
   ],
   "source": [
    "print(avg_sentence_length(article_text=article_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of complex words\n",
    "\n",
    "def syllable_count(word):\n",
    "    vowels = \"aeiou\"\n",
    "    word = word.lower()\n",
    "    syllables = 0\n",
    "    if word[0] in vowels:\n",
    "        syllables += 1\n",
    "    for index in range(1, len(word)):\n",
    "        if word[index] in vowels and word[index - 1] not in vowels:\n",
    "            syllables += 1\n",
    "    if word.endswith(\"es\") or word.endswith(\"ed\"):\n",
    "        syllables -= 1\n",
    "    if syllables == 0:\n",
    "        syllables += 1\n",
    "    return syllables\n",
    "\n",
    "def complex_word_count(text):\n",
    "    words = word_tokenize(text)\n",
    "    complex_words = [word for word in words if syllable_count(word) > 2]\n",
    "    return len(complex_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentage_of_complex_words(article_text):\n",
    "    return complex_word_count(article_text)/len(word_tokenize(article_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.264733395696913\n"
     ]
    }
   ],
   "source": [
    "print(percentage_of_complex_words(article_text=article_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fog Index\n",
    "\n",
    "def fog_index(article_text):\n",
    "    fog = (avg_sentence_length(article_text=article_text)+percentage_of_complex_words(article_text=article_text))\n",
    "    \n",
    "    return 0.4*fog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.922560024945433\n"
     ]
    }
   ],
   "source": [
    "print(fog_index(article_text=article_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 3: Average Number of Words Per Sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_number_of_words_per_sentence(article_text):\n",
    "    return len(word_tokenize(article_text))/len(sent_tokenize(article_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.541666666666664\n"
     ]
    }
   ],
   "source": [
    "print(average_number_of_words_per_sentence(article_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 4: Complex Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complex_word_count(text):\n",
    "    words = word_tokenize(text)\n",
    "    complex_words = [word for word in words if syllable_count(word) > 2]\n",
    "    return len(complex_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "283\n"
     ]
    }
   ],
   "source": [
    "print(complex_word_count(article_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 5: Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count(article_text):\n",
    "    cleaned_text = remove_stopwords(article_text, given_stop_words)\n",
    "    \n",
    "    # remove punctuations\n",
    "    words_without_punctuations = [word for word in cleaned_text if word not in string.punctuation]\n",
    "    \n",
    "    return len(words_without_punctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words in article: 1068\n",
      "After removing stopwords: 743\n",
      "612\n"
     ]
    }
   ],
   "source": [
    "print(word_count(article_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 6: Syllable Count Per Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def syllable_count_per_word(article_text):\n",
    "    syllables = 0\n",
    "    article_words=word_tokenize(article_text)\n",
    "    \n",
    "    for word in article_words:\n",
    "        \n",
    "        vowels = \"aeiou\"\n",
    "        word = word.lower()\n",
    "        \n",
    "        if word[0] in vowels:\n",
    "            syllables += 1\n",
    "        for index in range(1, len(word)):\n",
    "            if word[index] in vowels and word[index - 1] not in vowels:\n",
    "                syllables += 1\n",
    "        if word.endswith(\"es\") or word.endswith(\"ed\"):\n",
    "            syllables -= 1\n",
    "        if syllables == 0:\n",
    "            syllables += 1\n",
    "    \n",
    "    return syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1869\n"
     ]
    }
   ],
   "source": [
    "print(syllable_count_per_word(article_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 7: Personal Pronouns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def personal_pronouns(article_text):\n",
    "    pronouns = ['I', 'we', 'my', 'ours', 'us']\n",
    "    article_text = article_text.lower()\n",
    "    pronoun_count = 0\n",
    "    for pronoun in pronouns:\n",
    "        pattern = r'\\b' + pronoun + r'\\b'\n",
    "        pronoun_count += len(re.findall(pattern, article_text))\n",
    "    # Exclude the country name \"US\"\n",
    "    pronoun_count -= len(re.findall(r'\\bus\\b', article_text))\n",
    "    return pronoun_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(personal_pronouns(article_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 8: Average Word Length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_word_length(article_text):\n",
    "    count=0\n",
    "    article_words=word_tokenize(article_text)\n",
    "    \n",
    "    for word in article_words:\n",
    "        count+=len(word)\n",
    "    \n",
    "    return count/len(article_words)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.434050514499532\n"
     ]
    }
   ],
   "source": [
    "print(average_word_length(article_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
